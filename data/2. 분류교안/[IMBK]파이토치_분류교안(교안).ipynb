{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. DNN을 통한 분류"
      ],
      "metadata": {
        "id": "61P2E1eTnNPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ※ 앞으로 궁금할 상식: 분류 학습에서 왜 Cross Entropy를 사용할 때, output layer에 activation function을 안쓰는걸까?\n",
        "* (Binary) Cross Entropy에 이미 activation(예: sigmoid, softmax)이 내재되어 있어, 1차로 output의 features(Not categorical)를 activation 해준 후에, 2차로 CE loss 계산"
      ],
      "metadata": {
        "id": "xQwo7cWYnSCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "O0j-sh9BnTUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. wine.csv 데이터셋 기반 DNN 이진분류"
      ],
      "metadata": {
        "id": "QbvVAL-7P941"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('wine.csv')\n",
        "\n",
        "# 화이트 와인(0)인지 레드와인(1)인지\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1) # 2차원으로 만들어야함. 모델 예측은 2차원으로 나오기 때문\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(DNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 8)\n",
        "        self.layer2 = nn.Linear(8, 16)\n",
        "        self.layer3 = nn.Linear(16, 16)\n",
        "        self.layer4 = nn.Linear(16, 8)\n",
        "        self.layer5 = nn.Linear(8, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x = self.layer5(x)\n",
        "        return x\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = DNN(input_dim)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        y_pred = torch.sigmoid(y_pred) # 시그모이드를 통과해서 확률값 구함\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "        correct += (y_pred == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBRvFjdpQNW2",
        "outputId": "c3524113-faac-4ad3-960c-16d42ce359c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0722\n",
            "Epoch 2/10, Loss: 0.1342\n",
            "Epoch 3/10, Loss: 0.0167\n",
            "Epoch 4/10, Loss: 0.0266\n",
            "Epoch 5/10, Loss: 0.0045\n",
            "Epoch 6/10, Loss: 0.0111\n",
            "Epoch 7/10, Loss: 0.0039\n",
            "Epoch 8/10, Loss: 0.0046\n",
            "Epoch 9/10, Loss: 0.0054\n",
            "Epoch 10/10, Loss: 0.0381\n",
            "Accuracy: 0.9977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 실습) wine.csv 데이터셋 기반 DNN 이진분류를 누군가 코드를 망쳐놨다. 고쳐보자"
      ],
      "metadata": {
        "id": "y16XpWBQCI3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('wine.csv')\n",
        "\n",
        "# 화이트 와인(0)인지 레드와인(1)인지\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1) # 2차원으로 만들어야함. 모델 예측은 2차원으로 나오기 때문\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(DNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 8)\n",
        "        self.layer2 = nn.Linear(8, 16)\n",
        "        self.layer3 = nn.Linear(16, 16)\n",
        "        self.layer4 = nn.Linear(16, 8)\n",
        "        self.layer5 = nn.Linear(8,   )  # 수정\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x = self.layer5(x)\n",
        "        return x\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = DNN(input_dim)\n",
        "\n",
        "criterion = nn.          ()           # 수정\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        y_pred = torch.         (y_pred)   # 시그모이드를 통과해서 확률값 구함  # 수정\n",
        "        y_pred =                               # 수정\n",
        "        correct +=                             # 수정\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    accuracy =                        # 수정\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "uWjUjwfJCKie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. wine.csv 데이터셋 기반 DNN 이진분류\n",
        "\n",
        "1). accracy\n",
        "\n",
        "2). f1_score\n",
        "\n",
        "3). confusion matrix\n",
        "\n",
        "4). precision\n",
        "\n",
        "5). recall\n",
        "\n",
        "을 출력해보자"
      ],
      "metadata": {
        "id": "Kl7kpUWxx0r5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "df = pd.read_csv('wine.csv')\n",
        "\n",
        "# 화이트 와인(0)인지 레드와인(1)인지\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1) # 2차원으로 만들어야함. 모델 예측은 2차원으로 나오기 때문\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(DNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 8)\n",
        "        self.layer2 = nn.Linear(8, 16)\n",
        "        self.layer3 = nn.Linear(16, 16)\n",
        "        self.layer4 = nn.Linear(16, 8)\n",
        "        self.layer5 = nn.Linear(8, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x = self.layer5(x)\n",
        "        return x\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = DNN(input_dim)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_preds = []\n",
        "    y_trues = []\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        y_pred = torch.sigmoid(y_pred)  # 시그모이드를 통과해서 확률값 구함\n",
        "        y_pred = (y_pred > 0.5).float()  # 0.5를 기준으로 이진화\n",
        "        y_preds.extend(y_pred.view(-1).tolist())\n",
        "        y_trues.extend(y_batch.view(-1).tolist())\n",
        "\n",
        "    # 성능 지표 계산\n",
        "    accuracy = accuracy_score(y_trues, y_preds)\n",
        "    f1 = f1_score(y_trues, y_preds)\n",
        "    cm = confusion_matrix(y_trues, y_preds)\n",
        "    precision = precision_score(y_trues, y_preds)\n",
        "    recall = recall_score(y_trues, y_preds)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score: {f1:.4f}')\n",
        "    print(f'Confusion Matrix:\\n{cm}')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IfabJPiyF4O",
        "outputId": "0c832656-2220-443e-feae-1d76a0176fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0397\n",
            "Epoch 2/10, Loss: 0.0018\n",
            "Epoch 3/10, Loss: 0.0048\n",
            "Epoch 4/10, Loss: 0.0016\n",
            "Epoch 5/10, Loss: 0.3333\n",
            "Epoch 6/10, Loss: 0.0050\n",
            "Epoch 7/10, Loss: 0.0020\n",
            "Epoch 8/10, Loss: 0.0111\n",
            "Epoch 9/10, Loss: 0.0023\n",
            "Epoch 10/10, Loss: 0.0038\n",
            "Accuracy: 0.9977\n",
            "F1 Score: 0.9953\n",
            "Confusion Matrix:\n",
            "[[980   0]\n",
            " [  3 317]]\n",
            "Precision: 1.0000\n",
            "Recall: 0.9906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. wine.csv 데이터셋 기반 DNN 이진분류 - 클래스 불균형 해결\n",
        "\n",
        "SMOTE를 사용해보자"
      ],
      "metadata": {
        "id": "TQq0UII-4-Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "df = pd.read_csv('wine.csv')\n",
        "df['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "PnmOIYRu5CLK",
        "outputId": "e9efa922-8d0f-4ef7-f9a8-f39d684384a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "0    4898\n",
              "1    1599\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values   # 화이트 와인: 0, 레드 와인: 1\n",
        "\n",
        "# 데이터셋 분리 (훈련 및 테스트 셋)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# SMOTE 적용\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# SMOTE 적용 후 클래스 분포 확인\n",
        "print(f\"After SMOTE: \\n{pd.Series(y_train_resampled).value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lehX3XKk5LMj",
        "outputId": "55f63365-266f-49a4-c5b6-5b3234e2b006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After SMOTE: \n",
            "0    3918\n",
            "1    3918\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 데이터를 텐서로 변환\n",
        "X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_resampled, dtype=torch.float32).unsqueeze(1)  # 2차원으로 변환\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# 데이터셋과 데이터로더 준비\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# DNN 모델 정의\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(DNN, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 8)\n",
        "        self.layer2 = nn.Linear(8, 16)\n",
        "        self.layer3 = nn.Linear(16, 16)\n",
        "        self.layer4 = nn.Linear(16, 8)\n",
        "        self.layer5 = nn.Linear(8, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x = self.layer5(x)\n",
        "        return x\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = DNN(input_dim)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 모델 학습\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_preds = []\n",
        "    y_trues = []\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        y_pred = torch.sigmoid(y_pred)  # 시그모이드를 통과해서 확률값 구함\n",
        "        y_pred = (y_pred > 0.5).float()  # 0.5를 기준으로 이진화\n",
        "        y_preds.extend(y_pred.view(-1).tolist())\n",
        "        y_trues.extend(y_batch.view(-1).tolist())\n",
        "\n",
        "    # 성능 지표 계산\n",
        "    accuracy = accuracy_score(y_trues, y_preds)\n",
        "    f1 = f1_score(y_trues, y_preds)\n",
        "    cm = confusion_matrix(y_trues, y_preds)\n",
        "    precision = precision_score(y_trues, y_preds)\n",
        "    recall = recall_score(y_trues, y_preds)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(f'F1 Score: {f1:.4f}')\n",
        "    print(f'Confusion Matrix:\\n{cm}')\n",
        "    print(f'Precision: {precision:.4f}')\n",
        "    print(f'Recall: {recall:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfLyHaqf5bFe",
        "outputId": "c64418de-2f05-45a5-82c2-236de697045c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0177\n",
            "Epoch 2/10, Loss: 0.1369\n",
            "Epoch 3/10, Loss: 0.0109\n",
            "Epoch 4/10, Loss: 0.0091\n",
            "Epoch 5/10, Loss: 0.2100\n",
            "Epoch 6/10, Loss: 0.0045\n",
            "Epoch 7/10, Loss: 0.0733\n",
            "Epoch 8/10, Loss: 0.1047\n",
            "Epoch 9/10, Loss: 0.1912\n",
            "Epoch 10/10, Loss: 0.0055\n",
            "Accuracy: 0.9962\n",
            "F1 Score: 0.9922\n",
            "Confusion Matrix:\n",
            "[[977   3]\n",
            " [  2 318]]\n",
            "Precision: 0.9907\n",
            "Recall: 0.9938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 같이해보는 실습) 타이타닉 데이터셋으로 MLP 모델을 이용하여 생존분류를 해보자  "
      ],
      "metadata": {
        "id": "vOZNafnxQRy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\n",
        "df.dropna(inplace=True)\n",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "df['Embarked'] = LabelEncoder().fit_transform(df['Embarked'])\n",
        "\n",
        "X = df.drop('Survived', axis=1).values\n",
        "y = df['Survived'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 64)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.layer3 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.sigmoid(self.layer3(x))\n",
        "        return x\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = MLP(input_dim)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "        correct += (y_pred == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "Qcv4VMCtXpDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 타이타닉 데이터셋으로 MLP 모델을 이용하여 생존분류를 해보자 - 클래스 불균형 해결\n",
        "\n",
        "SMOTENC를 사용해보자"
      ],
      "metadata": {
        "id": "bBUDTksI5sZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE, SMOTENC\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "df = pd.read_csv('titanic.csv')\n",
        "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 각 클래스가 몇개인지 보자\n",
        "print(df['Survived'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7N1EOAc5-CV",
        "outputId": "896aa5c4-8041-4abb-9c37-0310ce432462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Survived\n",
            "0    424\n",
            "1    288\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 범주형 변수 인코딩\n",
        "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\n",
        "df['Embarked'] = LabelEncoder().fit_transform(df['Embarked'])\n",
        "\n",
        "X = df.drop('Survived', axis=1).values\n",
        "y = df['Survived'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 범주형 변수 인덱스 (Pclass, Sex, Embarked)\n",
        "categorical_features = [0, 1, 4]\n",
        "\n",
        "# SMOTE-NC 적용\n",
        "smote_nc = SMOTENC(categorical_features=categorical_features, random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote_nc.fit_resample(X_train, y_train)\n",
        "\n",
        "# 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 텐서변환\n",
        "X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_resampled, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# MLP 모델 정의\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 64)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.layer3 = nn.Linear(32, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.sigmoid(self.layer3(x))\n",
        "        return x\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "model = MLP(input_dim)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 모델 학습\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        y_pred = (y_pred > 0.5).float()\n",
        "        correct += (y_pred == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    accuracy = correct / total\n"
      ],
      "metadata": {
        "id": "3VwlnqHZ5s_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. iris.csv 데이터셋 기반 MLP 다중분류"
      ],
      "metadata": {
        "id": "m9WwLlFqP9zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv('iris.csv')\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "'''\n",
        "# 방법 1: nn.Sequential()과 add_module 사용\n",
        "\n",
        "model = nn.Sequential()\n",
        "model.add_module('fc1', nn.Linear(28*28*1, 100))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('fc2', nn.Linear(100, 100))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('fc3', nn.Linear(100, 10))\n",
        "\n",
        "# 방법 2: nn.Sequential() 안에 직접 레이어 정의\n",
        "model = nn.Sequential(\n",
        "     nn.Linear(28*28*1, 100),  # input_layer = 784, hidden_layer1 = 100\n",
        "     nn.ReLU(),\n",
        "     nn.Linear(100, 100),  # hidden_layer2 = 100, hidden_layer3 = 100\n",
        "     nn.ReLU(),\n",
        "     nn.Linear(100, 10)  # hidden_layer3 = 100, output_layer = 10\n",
        "     )\n",
        "'''\n",
        "# 방법 3: nn.Module을 상속하는 클래스 정의\n",
        "class MultiLayerRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiLayerRegression, self).__init__()\n",
        "        self.linear1 = nn.Linear(X_train.shape[1], 100)  # input_layer = X_train.shape[1], hidden_layer1 = 100\n",
        "        self.activate1 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(100, 100)  # hidden_layer2 = 100, hidden_layer3 = 100\n",
        "        self.activate2 = nn.ReLU()\n",
        "        self.linear3 = nn.Linear(100, len(set(y)))  # hidden_layer3 = 100, output_layer = len(set(y))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.linear1(x)\n",
        "        out2 = self.activate1(out1)\n",
        "        out3 = self.linear2(out2)\n",
        "        out4 = self.activate2(out3)\n",
        "        out5 = self.linear3(out4)\n",
        "        return out5\n",
        "\n",
        "model = MultiLayerRegression()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "patience = 5\n",
        "best_loss = float('inf')\n",
        "early_stop_counter = 0\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    if early_stop_counter >= patience:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = []\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        outputs = model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_pred.extend(predicted.numpy())\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "xn0yhhmJfkhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ★ 실무 실습) 배포 받은 \"신용카드 사용자 연체 예측\"를 통해 자신만의 코드를 작성 해보자\n",
        "\n",
        "[사람의 정보를 넣어서 신용을 분류예측 하는 모델을 만들어 보자!]\n",
        "\n",
        "1. credit: 사용자의 신용카드 대금 연체를 기준으로 한 신용도 (0,1,2)=> 낮을 수록 높은 신용의 신용카드 사용자를 의미함\n",
        "\n",
        "2. 하나의 포트폴리오가 될 수 있도록 시각화와 통계를 자유롭게 작성해보자.\n",
        "3. 이제까지 배운 분류 방법들을 통해 적용해보자.\n",
        "4. 모든 기법을 다 쓰는 것보다는 필요 할 것 같다는 코드만 작성해보기"
      ],
      "metadata": {
        "id": "bKsG3zdr8ga7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQnJzG75819K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 깃허브 울렁증 격파하기\n",
        "\n",
        "스토리: 누군가 나에게 분류에는 어떤 모델이 좋다고 써보라고 했다. 그 모델이 뭔진 모르겠다. 그럼에도 불구하고 갖다 써보자"
      ],
      "metadata": {
        "id": "Y03AMzHvjJv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) TabNet 스크립트 버전\n",
        "\n",
        "---\n",
        "https://github.com/huangyz0918/tabnet"
      ],
      "metadata": {
        "id": "vcpQ2J-DjOQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huangyz0918/tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW2VMc6QRobW",
        "outputId": "729f9b8e-2c04-4764-bd54-d9e8ba5779c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tabnet'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 33 (delta 11), reused 19 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (33/33), 10.74 MiB | 5.33 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmexF2htRsVh",
        "outputId": "d29a8c80-b405-4cf5-fac8-9d86e36f6aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tabnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/wine.csv /content/tabnet/data"
      ],
      "metadata": {
        "id": "LEwZmqyZR_TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neptune-client==0.9.18"
      ],
      "metadata": {
        "id": "Hp4qcBEUSMsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sparsemax"
      ],
      "metadata": {
        "id": "F16debVNScai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py  #메인에 train valid 싹다 있음. #main.py 로거 싹다 삭제"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFX5rgmPRx5o",
        "outputId": "c426e2a9-bd0b-4d12-a626-8b613ffb3c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device configuration: Cuda not available - check GPU configuration.\n",
            "Device configuration: Using cpu for training/inference\n",
            "Starting training...\n",
            "Training model with predictive objective\n",
            "Predictive - Epoch: 1, Step: 82, Total train loss: 0.2245, Validation criterion loss: 0.2147, Validation accuracy: 0.9108\n",
            "Predictive - Epoch: 2, Step: 164, Total train loss: 0.162, Validation criterion loss: 0.2831, Validation accuracy: 0.9292\n",
            "Predictive - Epoch: 3, Step: 246, Total train loss: 0.1112, Validation criterion loss: 0.2265, Validation accuracy: 0.9262\n",
            "Predictive - Epoch: 4, Step: 328, Total train loss: 0.0949, Validation criterion loss: 0.2372, Validation accuracy: 0.8992\n",
            "Predictive - Epoch: 5, Step: 410, Total train loss: 0.1109, Validation criterion loss: 0.328, Validation accuracy: 0.8838\n",
            "Predictive - Epoch: 6, Step: 492, Total train loss: 0.1038, Validation criterion loss: 0.2709, Validation accuracy: 0.8962\n",
            "Predictive - Epoch: 7, Step: 574, Total train loss: 0.1011, Validation criterion loss: 0.2778, Validation accuracy: 0.9023\n",
            "Predictive - Epoch: 8, Step: 656, Total train loss: 0.0926, Validation criterion loss: 0.286, Validation accuracy: 0.8923\n",
            "Predictive - Epoch: 9, Step: 738, Total train loss: 0.0919, Validation criterion loss: 0.0838, Validation accuracy: 0.9785\n",
            "Predictive - Epoch: 10, Step: 820, Total train loss: 0.0811, Validation criterion loss: 0.1946, Validation accuracy: 0.9415\n",
            "Saving model to: runs/forest_cover/1725189585_forest_cover_predictive_model_final.pt\n",
            "Device configuration: Cuda not available - check GPU configuration.\n",
            "Device configuration: Using cpu for training/inference\n",
            "/content/tabnet/tabnet/train.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_params, model_state_dict = torch.load(\n",
            "TabNet accuracy: 0.942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "-lxHkXboRv62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) TabNet 울렁증 버전\n",
        "\n",
        "---\n",
        "https://github.com/dreamquark-ai/tabnet\n"
      ],
      "metadata": {
        "id": "_1BzGOsmjvIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "id": "nSG39zxgju1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 데이터 로드\n",
        "df = pd.read_csv('wine.csv')\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# 데이터셋을 훈련 세트와 테스트 세트로 분할\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "\n",
        "# TabNetClassifier 초기화 및 학습\n",
        "clf = TabNetClassifier()\n",
        "\n",
        "# GPU 모드일때\n",
        "#import torch\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#clf = TabNetClassifier(device_name=device.type)  # GPU 사용 설정\n",
        "\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=128\n",
        ")\n",
        "\n",
        "# 예측\n",
        "preds = clf.predict(X_valid)\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_valid, preds)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "Tz90wSGUM0Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) TabTransformer 오피셜이 공개되지 않은 버전\n",
        "\n",
        "---\n",
        "\n",
        "https://github.com/lucidrains/tab-transformer-pytorch\n"
      ],
      "metadata": {
        "id": "ENu-Vd2vjVTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tab-transformer-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cso1MB3ajYSD",
        "outputId": "1ef73cc8-75da-4ece-ee64-352276bfaaa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tab-transformer-pytorch\n",
            "  Downloading tab_transformer_pytorch-0.3.0-py3-none-any.whl.metadata (690 bytes)\n",
            "Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from tab-transformer-pytorch) (0.8.0)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from tab-transformer-pytorch) (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->tab-transformer-pytorch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->tab-transformer-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->tab-transformer-pytorch) (1.3.0)\n",
            "Downloading tab_transformer_pytorch-0.3.0-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: tab-transformer-pytorch\n",
            "Successfully installed tab-transformer-pytorch-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tab_transformer_pytorch import TabTransformer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('wine.csv')\n",
        "\n",
        "# 독립 변수와 종속 변수 분리\n",
        "X = df.drop('class', axis=1).values  # class 열 제외한 나머지 열 사용\n",
        "y = df['class'].values  # 0 또는 1로 레이블링된 와인 품질\n",
        "\n",
        "# 데이터셋 분리 (훈련/테스트)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# TabTransformer 모델 정의\n",
        "model = TabTransformer(\n",
        "    categories=[],\n",
        "    num_continuous=X_train_tensor.shape[1],  # 연속형 변수의 개수\n",
        "    dim=32,  # 모델 차원\n",
        "    dim_out=1,  # 이진 분류 출력\n",
        "    depth=6,  # 모델 깊이\n",
        "    heads=8,  # 멀티헤드 어텐션 헤드 수\n",
        "    attn_dropout=0.1,  # 어텐션 드롭아웃\n",
        "    ff_dropout=0.1,  # 피드포워드 드롭아웃\n",
        "    mlp_hidden_mults=(4, 2),  # MLP의 히든 레이어 크기 비율\n",
        "    mlp_act=nn.ReLU(),  # MLP의 활성화 함수\n",
        ")\n",
        "\n",
        "# 모델 학습 준비\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 예측 및 손실 계산\n",
        "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_train_tensor)  # 범주형 변수가 없으므로 비어있는 텐서를 줘야함.\n",
        "    loss = criterion(y_pred, y_train_tensor)\n",
        "\n",
        "    # 역전파 및 최적화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 5 == 0 :\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(torch.empty((X_train_tensor.shape[0], 0), dtype=torch.int64), X_test_tensor)\n",
        "    y_pred = torch.sigmoid(y_pred)\n",
        "    y_pred_class = (y_pred > 0.5).float()\n",
        "\n",
        "    accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
        "    print(f'Valid Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvES6NiQ9iRB",
        "outputId": "058b69b8-e9f7-457a-bbb2-5fe0e0d72d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 0.7227\n",
            "Epoch 10/50, Loss: 0.6908\n",
            "Epoch 15/50, Loss: 0.6619\n",
            "Epoch 20/50, Loss: 0.6333\n",
            "Epoch 25/50, Loss: 0.6018\n",
            "Epoch 30/50, Loss: 0.5647\n",
            "Epoch 35/50, Loss: 0.5207\n",
            "Epoch 40/50, Loss: 0.4710\n",
            "Epoch 45/50, Loss: 0.4176\n",
            "Epoch 50/50, Loss: 0.3623\n",
            "Valid Accuracy: 0.9738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) TabTransformer 오피셜이 공개되지 않은 버전 - 타이타닉\n",
        "\n",
        "---\n",
        "\n",
        "https://github.com/lucidrains/tab-transformer-pytorch\n"
      ],
      "metadata": {
        "id": "3srp0vERA73j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tab_transformer_pytorch import TabTransformer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "\n",
        "# 필요한 열 선택 및 전처리\n",
        "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# 범주형 변수 인코딩\n",
        "label_encoders = {}\n",
        "for col in ['Pclass', 'Sex', 'Embarked']:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "\n",
        "X = df.drop('Survived', axis=1).values  # 'Survived' 열 제외한 나머지 열 사용\n",
        "y = df['Survived'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 연속형 변수만 정규화 적용\n",
        "scaler = StandardScaler()\n",
        "X_train[:, [2, 3]] = scaler.fit_transform(X_train[:, [2, 3]])  # 연속형 변수 (Age, Fare)만 정규화\n",
        "X_test[:, [2, 3]] = scaler.transform(X_test[:, [2, 3]])\n",
        "\n",
        "X_train_categ = torch.tensor(X_train[:, [0, 1, 4]], dtype=torch.int64)  # 범주형 변수 (Pclass, Sex, Embarked)\n",
        "X_train_cont = torch.tensor(X_train[:, [2, 3]], dtype=torch.float32)  # 연속형 변수 (Age, Fare)\n",
        "X_test_categ = torch.tensor(X_test[:, [0, 1, 4]], dtype=torch.int64)\n",
        "X_test_cont = torch.tensor(X_test[:, [2, 3]], dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# TabTransformer 모델 정의\n",
        "model = TabTransformer(\n",
        "    categories=(3, 2, 3),  # Pclass, Sex, Embarked의 고유 값 개수\n",
        "    num_continuous=X_train_cont.shape[1],  # 연속형 변수의 개수\n",
        "    dim=32,  # 모델 차원\n",
        "    dim_out=1,  # 이진 분류 출력\n",
        "    depth=6,  # 모델 깊이\n",
        "    heads=8,  # 멀티헤드 어텐션 헤드 수\n",
        "    attn_dropout=0.1,  # 어텐션 드롭아웃\n",
        "    ff_dropout=0.1,  # 피드포워드 드롭아웃\n",
        "    mlp_hidden_mults=(4, 2),  # MLP의 히든 레이어 크기 비율\n",
        "    mlp_act=nn.ReLU(),  # MLP의 활성화 함수\n",
        ")\n",
        "\n",
        "# 모델 학습 준비\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 예측 및 손실 계산\n",
        "    y_pred = model(X_train_categ, X_train_cont)  # 범주형 및 연속형 변수 모두 전달\n",
        "    loss = criterion(y_pred, y_train_tensor)\n",
        "\n",
        "    # 역전파 및 최적화\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_categ, X_test_cont)\n",
        "    y_pred = torch.sigmoid(y_pred)\n",
        "    y_pred_class = (y_pred > 0.5).float()\n",
        "\n",
        "    accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
        "    print(f'Valid Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgKdicetA4em",
        "outputId": "351a4e0d-642d-4a54-d666-c2f8abd3ee83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 0.4601\n",
            "Epoch 10/50, Loss: 0.4423\n",
            "Epoch 15/50, Loss: 0.4370\n",
            "Epoch 20/50, Loss: 0.4333\n",
            "Epoch 25/50, Loss: 0.4311\n",
            "Epoch 30/50, Loss: 0.4291\n",
            "Epoch 35/50, Loss: 0.4299\n",
            "Epoch 40/50, Loss: 0.4284\n",
            "Epoch 45/50, Loss: 0.4265\n",
            "Epoch 50/50, Loss: 0.4268\n",
            "Valid Accuracy: 0.7762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ★ 실무 실습) 배포 받은 \"Loan-Status-Prediction\"를 통해 자신만의 코드를 작성 해보자\n",
        "\n",
        "1. 대출자가 상환할 가능성이 있는지를 분류하는 모델을 만들 것이다.\n",
        "2. 하나의 포트폴리오가 될 수 있도록 시각화와 통계를 자유롭게 작성해보자.\n",
        "3. 이제까지 배운 분류 방법들을 통해 적용해보자.\n",
        "4. 모든 기법을 다 쓰는 것보다는 필요 할 것 같다는 코드만 작성해보기\n"
      ],
      "metadata": {
        "id": "DZk0HEkbTHJz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24koOX2QXA8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  위 코드에서 어떤 기법들을 썼었고 왜 그것들을 썼는지 서술 하시오."
      ],
      "metadata": {
        "id": "JPgEEjb4XCov"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OmLB0oyrXB9S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}